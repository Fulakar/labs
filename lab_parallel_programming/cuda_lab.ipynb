{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, njit, jit\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "np.random.seed = 12312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce RTX 3060'                              [SUPPORTED]\n",
      "                      Compute Capability: 8.6\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 5\n",
      "                                    UUID: GPU-fab3ebaa-82c9-7907-6668-b141e026c09b\n",
      "                                Watchdog: Enabled\n",
      "                            Compute Mode: WDDM\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычитание векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit()\n",
    "def vector_diff(vector_1, vector_2, vector_3):\n",
    "    i = cuda.grid(1)\n",
    "    vector_3[i] = vector_1[i] - vector_2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_diff_cuda(vector_1, vector_2):\n",
    "    block = 256\n",
    "    grid = math.ceil(len(vector_1) / block)\n",
    "    print('size of grid:', grid, 'size of block:', block)\n",
    "\n",
    "    s = time.time()\n",
    "    vector_1_d = cuda.to_device(vector_1)\n",
    "    vector_2_d = cuda.to_device(vector_2)\n",
    "    vector_r_d = cuda.device_array_like(vector_1)\n",
    "    f = time.time()\n",
    "    print('loading time:', f - s)\n",
    "\n",
    "    s = time.time()\n",
    "    vector_diff[grid, block](vector_1, vector_2, vector_r_d)\n",
    "    f = time.time()\n",
    "    print('calculation time:', f - s)\n",
    "\n",
    "    return vector_r_d.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000000\n",
    "x = np.random.random(N)\n",
    "y = np.random.random(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of grid: 3907 size of block: 256\n",
      "loading time: 0.0890202522277832\n",
      "calculation time: 0.2355334758758545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Py\\Lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3265540599822998"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "vector_cuda = vector_diff_cuda(x , y)\n",
    "finish = time.time()\n",
    "finish - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030014514923095703"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "vector_np = x - y\n",
    "finish = time.time()\n",
    "finish - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(vector_cuda, vector_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск символов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def str_bins(text, bin):\n",
    "    i = cuda.grid(1)\n",
    "    if i <= len(text):\n",
    "        cuda.atomic.add(bin, text[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', encoding='Utf-8') as file:\n",
    "    text = file.read()\n",
    "text = list(text)\n",
    "for i in range(len(text)):\n",
    "    text[i] = ord(text[i])\n",
    "\n",
    "text = np.array(text)\n",
    "bins_letters = np.zeros(text.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading time: 0.0009999275207519531\n",
      "calculation time: 0.0009996891021728516\n",
      "loading to host time: 0.0020017623901367188\n",
      "0.009002685546875\n"
     ]
    }
   ],
   "source": [
    "TPB = 32\n",
    "BPG = math.ceil(len(text) / TPB)\n",
    "\n",
    "s1 = time.time()\n",
    "s = time.time()\n",
    "text_device = cuda.to_device(text)\n",
    "bins_letters_device = cuda.to_device(bins_letters)\n",
    "f = time.time()\n",
    "print('loading time:', f - s)\n",
    "\n",
    "s = time.time()\n",
    "str_bins[BPG, TPB](text_device, bins_letters_device)\n",
    "f = time.time()\n",
    "print('calculation time:', f - s)\n",
    "\n",
    "s = time.time()\n",
    "bins_letters = bins_letters_device.copy_to_host()\n",
    "f = time.time()\n",
    "print('loading to host time:', f - s)\n",
    "\n",
    "bins_cuda = {}\n",
    "for i in range(1, len(np.unique(bins_letters))):\n",
    "    value = np.unique(bins_letters)[i]\n",
    "    for i in range(len(np.where(bins_letters == value)[0])):\n",
    "        key = np.where(bins_letters == value)[0][i]\n",
    "        bins_cuda[chr(key)] = value\n",
    "print(time.time() - s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculation cpu time:0.07601547241210938\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "bins_cpu = {}\n",
    "for i in range(len(text)):\n",
    "    if chr(text[i]) in bins_cpu:\n",
    "        bins_cpu[chr(text[i])] += 1\n",
    "    else:\n",
    "        bins_cpu[chr(text[i])] = 1\n",
    "f = time.time()\n",
    "print(f'calculation cpu time:{f - s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перемножение матриц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrx_mnoj_cuda(x, y):\n",
    "    if x.shape[1] == y.shape[0]:\n",
    "        block = (32, 32)\n",
    "        grid = (math.ceil(x.shape[0] / block[0]), math.ceil(y.shape[1] / block[1]))\n",
    "        print('size of block:', block, 'size of grid:', grid)\n",
    "      \n",
    "      \n",
    "        s = time.time()\n",
    "        shape = (x.shape[0], y.shape[1])\n",
    "        x_d = cuda.to_device(x)\n",
    "        y_d = cuda.to_device(y)\n",
    "        r_d = cuda.device_array(shape)\n",
    "        f = time.time()\n",
    "        print('loading time:', f - s)\n",
    "\n",
    "        s = time.time()\n",
    "        matmul[grid, block](x_d, y_d, r_d)\n",
    "        f = time.time()\n",
    "        print('calculation time:', f - s)\n",
    "        \n",
    "        s = time.time()\n",
    "        r_d.copy_to_host()\n",
    "        f = time.time()\n",
    "        print(f'copy to host time: {f - s}')\n",
    "\n",
    "        return r_d\n",
    "    else:\n",
    "        raise ValueError('col != row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_1 = np.random.random((5000, 8000))\n",
    "matrix_2 = np.random.random((8000, 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of block: (32, 32) size of grid: (157, 157)\n",
      "loading time: 0.1090233325958252\n",
      "calculation time: 0.0\n",
      "copy to host time: 9.409118890762329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.53214693069458"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "matrix_r_cuda = matrx_mnoj_cuda(matrix_1, matrix_2)\n",
    "finish = time.time()\n",
    "finish - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6853797435760498"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "matrix_r_np = matrix_1 @ matrix_2\n",
    "finish = time.time()\n",
    "finish - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(matrix_r_cuda, matrix_r_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирование изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\New\\AppData\\Local\\Temp\\ipykernel_7880\\3235599202.py:1: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def coding_cpu(palitre, img):\n",
    "    img_coding = np.zeros([img.shape[0], img.shape[1]])\n",
    "\n",
    "    for i in range(img.shape[0]):\n",
    "        #print(f'{i / img.shape[0] * 100}%')\n",
    "        \n",
    "        for j in range(img.shape[1]):\n",
    "            img_coding[i, j] = np.where((palitre == img[i, j]).all(axis=1))[0][0]\n",
    "\n",
    "    return img_coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def coding_cuda(palitre, img, img_r):\n",
    "    x, y = cuda.grid(2)\n",
    "    if x <= img.shape[0] and y <= img.shape[1]:\n",
    "        for i in range(palitre.shape[0]):\n",
    "            value = 0\n",
    "            for j in range(3):\n",
    "                if palitre[i, j] == img[x, y, j]:\n",
    "                    value += 1\n",
    "            if value == 3:\n",
    "                img_r[x, y] = i\n",
    "                break\n",
    "            else:\n",
    "                value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def coding_cuda_const(palitre, img, img_r):\n",
    "    x, y = cuda.grid(2)\n",
    "    palitre_c = cuda.const.array_like(palitre)\n",
    "    if x <= img.shape[0] and y <= img.shape[1]:\n",
    "        for i in range(palitre_c.shape[0]):\n",
    "            value = 0\n",
    "            for j in range(3):\n",
    "                if palitre_c[i, j] == img[x, y, j]:\n",
    "                    value += 1\n",
    "            if value == 3:\n",
    "                img_r[x, y] = i\n",
    "                break\n",
    "            else:\n",
    "                value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\New\\AppData\\Local\\Temp\\ipykernel_7880\\1944400083.py:1: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def decoding_cpu(palitre, img):\n",
    "    img_decoding = np.zeros([img.shape[0], img.shape[1], 3])\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            img_decoding[i, j] = palitre[int(img[i, j])]\n",
    "    return img_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def decoding_cuda(palitre, img, img_r):\n",
    "    x, y = cuda.grid(2)\n",
    "    palitre = cuda.const\n",
    "    if x <= img.shape[0] and y <= img.shape[1]:\n",
    "        for w in range(3):\n",
    "            img_r[x, y, w] = palitre[int(img[x, y]), w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def decoding_cuda_const(palitre, img, img_r):\n",
    "    x, y = cuda.grid(2)\n",
    "    palitre_c = cuda.const.array_like(palitre)\n",
    "    if x <= img.shape[0] and y <= img.shape[1]:\n",
    "        for w in range(3):\n",
    "            img_r[x, y, w] = palitre_c[int(img[x, y]), w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coding_decoding_cuda(palitre, img):\n",
    "    TPB = (16, 16)\n",
    "    BPG = (math.ceil(img.shape[0] / TPB[0]), math.ceil(img.shape[1] / TPB[1]))\n",
    "\n",
    "    palitre_d = cuda.to_device(palitre)\n",
    "    img_d = cuda.to_device(img)\n",
    "    img_coding_d = cuda.device_array([img.shape[0], img.shape[1]])\n",
    "    img_decoding_d = cuda.device_array([img.shape[0], img.shape[1], int(3)])\n",
    "\n",
    "    coding_cuda[BPG, TPB](palitre_d, img_d, img_coding_d)\n",
    "    decoding_cuda[BPG, TPB](palitre_d, img_coding_d, img_decoding_d)\n",
    "    return img_decoding_d.copy_to_host(), img_coding_d.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coding_decoding_cuda_const(palitre, img):\n",
    "    TPB = (16, 16)\n",
    "    BPG = (math.ceil(img.shape[0] / TPB[0]), math.ceil(img.shape[1] / TPB[1]))\n",
    "\n",
    "    img_d = cuda.to_device(img)\n",
    "    img_coding_d = cuda.device_array([img.shape[0], img.shape[1]])\n",
    "    img_decoding_d = cuda.device_array([img.shape[0], img.shape[1], int(3)])\n",
    "\n",
    "    coding_cuda[BPG, TPB](palitre, img_d, img_coding_d)\n",
    "    decoding_cuda[BPG, TPB](palitre, img_coding_d, img_decoding_d)\n",
    "    return img_decoding_d.copy_to_host(), img_coding_d.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lab_4.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "colors = list()\n",
    "for i in range(img.shape[0]):\n",
    "    for j in range(img.shape[1]):\n",
    "        colors.append(tuple(img[i , j].tolist()))\n",
    "print(len(colors) == (img.shape[0] * img.shape[1]))\n",
    "colors = set(colors)\n",
    "colors = list(colors)\n",
    "colors = sorted(colors)\n",
    "palitre = []\n",
    "for i in range(len(colors)):\n",
    "    palitre.append(list(colors[i]))\n",
    "del colors\n",
    "palitre = np.array(palitre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of coding, decoding with cpu: 57.37299919128418\n",
      "True:True\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "cpu_coding = coding_cpu(palitre, img)\n",
    "cpu_decoding = decoding_cpu(palitre, cpu_coding)\n",
    "f = time.time()\n",
    "print(f'Time of coding, decoding with cpu: {f - s}')\n",
    "print(f'True:{np.allclose(img, cpu_decoding)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of coding, decoding with cuda: 0.23005461692810059\n",
      "True:True\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "cuda_decoding, cuda_coding = coding_decoding_cuda(palitre, img)\n",
    "f = time.time()\n",
    "print(f'Time of coding, decoding with cuda: {f - s}')\n",
    "print(f'True:{np.allclose(img, cuda_decoding)}')\n",
    "# print(np.allclose(img_coding, cuda_coding))\n",
    "# print(np.where((img == cuda_coding) == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of coding, decoding with cuda: 0.12202811241149902\n",
      "True:True\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "cuda_decoding, cuda_coding = coding_decoding_cuda_const(palitre, img)\n",
    "f = time.time()\n",
    "print(f'Time of coding, decoding with cuda: {f - s}')\n",
    "print(f'True:{np.allclose(img, cuda_decoding)}')\n",
    "# print(np.allclose(img_coding, cuda_coding))\n",
    "# print(np.where((img == cuda_coding) == False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
